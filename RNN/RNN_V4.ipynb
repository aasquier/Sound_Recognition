{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/Users/carsoncook/Dev/CS445/Group_Project_cs445')\n",
    "import extractFeatures as ef\n",
    "import importantFeatures as imp_f\n",
    "\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import SimpleRNN, LSTM, GRU \n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Constants\n",
    "N_CLASSES = 10\n",
    "AUD_MSK = imp_f.importantAudioFeatures\n",
    "IM_MSK = imp_f.importantImageFeatures\n",
    "FULL_MSK = imp_f.importantCombinedFeatures\n",
    "\n",
    "# Hyper Parameters\n",
    "UNITS = 256\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 100\n",
    "# DROPOUT = (.25, .5)\n",
    "IMAGE_PATH = 'images_feature_select/'\n",
    "ACC_PATH = 'accuracies_feature_select/'\n",
    "TXT_FILE = 'accuracies_v3.txt'\n",
    "\n",
    "np.random.seed(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN LSTM\n",
    "def build_and_run_model(X_train, X_test, Y_train, Y_test, units, rows, cols, batch_size, epochs, fold, prefix):\n",
    "    X_train = X_train.reshape(-1, rows, cols)\n",
    "    X_test = X_test.reshape(-1, rows, cols)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units, input_shape=(rows, cols),\n",
    "#                    return_sequences=True,\n",
    "                   activation='tanh',\n",
    "                   recurrent_activation ='sigmoid',\n",
    "                   unit_forget_bias=True,\n",
    "                  ))\n",
    "#     model.add(LSTM(units, input_shape=(rows, cols),\n",
    "#                    activation='tanh',\n",
    "#                    recurrent_activation ='sigmoid',\n",
    "#                    unit_forget_bias=True,\n",
    "#                   ))\n",
    "    model.add(Dense(UNITS, activation='sigmoid'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(N_CLASSES, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "    model.fit(X_train, Y_train,\n",
    "             batch_size=batch_size,\n",
    "             epochs=epochs,\n",
    "             verbose=1,\n",
    "             validation_data=(X_test, Y_test))\n",
    "    score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "    preds = model.predict_classes(X_test)\n",
    "    y_test = np.argmax(Y_test, axis=1)\n",
    "    # cm = confusion_matrix(y_test, preds)\n",
    "    output = np.vstack((preds, y_test)).T\n",
    "    file_name = '{}{}_fold_{}_accs.csv'.format(ACC_PATH, prefix, fold)\n",
    "    np.savetxt(file_name, output, fmt='%d', delimiter=',', header='predicted,actual')\n",
    "    print(\"Score: \", score)\n",
    "    return score[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assess model using cross validation\n",
    "def run_k_fold_cv(k, acc_file, units, a_shape, im_shape, full_shape):\n",
    "    accs = np.zeros(shape=(k,3), dtype='float64')\n",
    "    for i in range(k):\n",
    "        (aud_X_train, aud_X_test, aud_y_train, aud_y_test,\n",
    "        im_X_train, im_X_test, im_y_train, im_y_test,\n",
    "        aud_X_train_norm, aud_X_test_norm, aud_y_train_norm, aud_y_test_norm,\n",
    "        im_X_train_norm, im_X_test_norm, im_y_train_norm, im_y_test_norm) = ef.crossValidationIteration(i)\n",
    "        \n",
    "        \n",
    "        # Smash features together\n",
    "        full_X_train = np.concatenate((aud_X_train, im_X_train))\n",
    "        full_X_test = np.concatenate((aud_X_test, im_X_test))\n",
    "        full_y_train = np.hstack((aud_y_train, im_y_train))\n",
    "        full_y_test = np.hstack((aud_y_test, im_y_test))\n",
    "\n",
    "        # One Hot Encoding\n",
    "        aud_Y_train = keras.utils.to_categorical(aud_y_train, N_CLASSES)\n",
    "        aud_Y_test = keras.utils.to_categorical(aud_y_test, N_CLASSES)\n",
    "        im_Y_train = keras.utils.to_categorical(im_y_train, N_CLASSES)\n",
    "        im_Y_test = keras.utils.to_categorical(im_y_test, N_CLASSES)\n",
    "        full_Y_train = keras.utils.to_categorical(full_y_train, N_CLASSES)\n",
    "        full_Y_test = keras.utils.to_categorical(full_y_test, N_CLASSES)\n",
    "        \n",
    "        accs[i, 0] = build_and_run_model(aud_X_train[:, AUD_MSK], aud_X_test[:, AUD_MSK],\n",
    "                                         aud_Y_train, aud_Y_test,\n",
    "                                         units, a_shape[0], a_shape[1], BATCH_SIZE,\n",
    "                                         EPOCHS, i, 'aud')\n",
    "        accs[i, 1] = build_and_run_model(im_X_train[:, IM_MSK], im_X_test[:, IM_MSK],\n",
    "                                         im_Y_train, im_Y_test,\n",
    "                                         units, im_shape[0], im_shape[1], BATCH_SIZE,\n",
    "                                         EPOCHS, i, 'im')\n",
    "        accs[i, 2] = build_and_run_model(full_X_train[:, FULL_MSK], full_X_test[:, FULL_MSK],\n",
    "                                         full_Y_train, full_Y_test,\n",
    "                                         units, im_shape[0], im_shape[1], BATCH_SIZE,\n",
    "                                         EPOCHS, i, 'comb')\n",
    "\n",
    "        with open (acc_file, 'a') as outfile:\n",
    "            outfile.write('\\n[Fold: {}]\\nAudio Acc: {}\\nImage Acc: {}\\nCombined Acc: {}'.format(i, accs[i, 0], accs[i, 1], accs[i, 2]))\n",
    "    with open (acc_file, 'a') as outfile:\n",
    "        avgs = accs.mean(axis = 0)\n",
    "        outfile.write('\\nAvg. Audio Acc: {}, Avg. Image Acc: {}, Avg. Combined Acc: {}'.format(\n",
    "            avgs[0], avgs[1], avgs[2]\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7859 samples, validate on 873 samples\n",
      "Epoch 1/100\n",
      "7859/7859 [==============================] - 2s 196us/step - loss: 1.8636 - acc: 0.3588 - val_loss: 1.7313 - val_acc: 0.4124\n",
      "Epoch 2/100\n",
      "7859/7859 [==============================] - 1s 95us/step - loss: 1.3347 - acc: 0.5679 - val_loss: 1.6795 - val_acc: 0.5178\n",
      "Epoch 3/100\n",
      "7859/7859 [==============================] - 1s 94us/step - loss: 1.0853 - acc: 0.6561 - val_loss: 1.6831 - val_acc: 0.5212\n",
      "Epoch 4/100\n",
      "7859/7859 [==============================] - 1s 92us/step - loss: 0.9125 - acc: 0.7112 - val_loss: 1.6926 - val_acc: 0.5223\n",
      "Epoch 5/100\n",
      "7859/7859 [==============================] - 1s 95us/step - loss: 0.7850 - acc: 0.7603 - val_loss: 1.7760 - val_acc: 0.5235\n",
      "Epoch 6/100\n",
      "7859/7859 [==============================] - 1s 95us/step - loss: 0.6898 - acc: 0.7921 - val_loss: 1.8607 - val_acc: 0.5052\n",
      "Epoch 7/100\n",
      "7859/7859 [==============================] - 1s 98us/step - loss: 0.6047 - acc: 0.8214 - val_loss: 1.8227 - val_acc: 0.5464\n",
      "Epoch 8/100\n",
      "7859/7859 [==============================] - 1s 94us/step - loss: 0.5411 - acc: 0.8324 - val_loss: 1.8692 - val_acc: 0.5212\n",
      "Epoch 9/100\n",
      "7859/7859 [==============================] - 1s 95us/step - loss: 0.4861 - acc: 0.8504 - val_loss: 1.9795 - val_acc: 0.5235\n",
      "Epoch 10/100\n",
      "7859/7859 [==============================] - 1s 96us/step - loss: 0.4345 - acc: 0.8687 - val_loss: 2.0109 - val_acc: 0.5624\n",
      "Epoch 11/100\n",
      "7859/7859 [==============================] - 1s 96us/step - loss: 0.3984 - acc: 0.8768 - val_loss: 2.0144 - val_acc: 0.5384\n",
      "Epoch 12/100\n",
      "7859/7859 [==============================] - 1s 97us/step - loss: 0.3660 - acc: 0.8864 - val_loss: 2.1589 - val_acc: 0.5441\n",
      "Epoch 13/100\n",
      "7859/7859 [==============================] - 1s 99us/step - loss: 0.3272 - acc: 0.8997 - val_loss: 2.2750 - val_acc: 0.5063\n",
      "Epoch 14/100\n",
      "7859/7859 [==============================] - 1s 98us/step - loss: 0.3045 - acc: 0.9069 - val_loss: 2.2309 - val_acc: 0.5613\n",
      "Epoch 15/100\n",
      "7859/7859 [==============================] - 1s 97us/step - loss: 0.2809 - acc: 0.9139 - val_loss: 2.2813 - val_acc: 0.5395\n",
      "Epoch 16/100\n",
      "7859/7859 [==============================] - 1s 96us/step - loss: 0.2552 - acc: 0.9245 - val_loss: 2.3146 - val_acc: 0.5475\n",
      "Epoch 17/100\n",
      "7859/7859 [==============================] - 1s 96us/step - loss: 0.2327 - acc: 0.9300 - val_loss: 2.4377 - val_acc: 0.5189\n",
      "Epoch 18/100\n",
      "7859/7859 [==============================] - 1s 100us/step - loss: 0.2180 - acc: 0.9342 - val_loss: 2.4638 - val_acc: 0.5246\n",
      "Epoch 19/100\n",
      "7859/7859 [==============================] - 1s 95us/step - loss: 0.2036 - acc: 0.9384 - val_loss: 2.5009 - val_acc: 0.5246\n",
      "Epoch 20/100\n",
      "7859/7859 [==============================] - 1s 97us/step - loss: 0.1822 - acc: 0.9449 - val_loss: 2.3945 - val_acc: 0.5510\n",
      "Epoch 21/100\n",
      "7859/7859 [==============================] - 1s 96us/step - loss: 0.1734 - acc: 0.9462 - val_loss: 2.6912 - val_acc: 0.4983\n",
      "Epoch 22/100\n",
      "7859/7859 [==============================] - 1s 98us/step - loss: 0.1559 - acc: 0.9524 - val_loss: 2.7455 - val_acc: 0.5052\n",
      "Epoch 23/100\n",
      "7859/7859 [==============================] - 1s 101us/step - loss: 0.1416 - acc: 0.9548 - val_loss: 2.6653 - val_acc: 0.5017\n",
      "Epoch 24/100\n",
      "7859/7859 [==============================] - 1s 97us/step - loss: 0.1338 - acc: 0.9622 - val_loss: 2.8575 - val_acc: 0.4926\n",
      "Epoch 25/100\n",
      "7859/7859 [==============================] - 1s 97us/step - loss: 0.1320 - acc: 0.9580 - val_loss: 2.8698 - val_acc: 0.4914\n",
      "Epoch 26/100\n",
      "7859/7859 [==============================] - 1s 97us/step - loss: 0.1110 - acc: 0.9698 - val_loss: 2.8188 - val_acc: 0.5361\n",
      "Epoch 27/100\n",
      "7859/7859 [==============================] - 1s 96us/step - loss: 0.1005 - acc: 0.9695 - val_loss: 2.9296 - val_acc: 0.4983\n",
      "Epoch 28/100\n",
      "7859/7859 [==============================] - 1s 101us/step - loss: 0.1022 - acc: 0.9715 - val_loss: 3.1190 - val_acc: 0.4983\n",
      "Epoch 29/100\n",
      "7859/7859 [==============================] - 1s 96us/step - loss: 0.0899 - acc: 0.9728 - val_loss: 3.1236 - val_acc: 0.4811\n",
      "Epoch 30/100\n",
      "7859/7859 [==============================] - 1s 99us/step - loss: 0.0826 - acc: 0.9758 - val_loss: 3.0978 - val_acc: 0.5063\n",
      "Epoch 31/100\n",
      "7859/7859 [==============================] - 1s 101us/step - loss: 0.0827 - acc: 0.9781 - val_loss: 3.2889 - val_acc: 0.4467\n",
      "Epoch 32/100\n",
      "7859/7859 [==============================] - 1s 103us/step - loss: 0.0714 - acc: 0.9782 - val_loss: 3.0354 - val_acc: 0.5086\n",
      "Epoch 33/100\n",
      "7859/7859 [==============================] - 1s 107us/step - loss: 0.0737 - acc: 0.9768 - val_loss: 3.3221 - val_acc: 0.4708\n",
      "Epoch 34/100\n",
      "7859/7859 [==============================] - 1s 98us/step - loss: 0.0676 - acc: 0.9790 - val_loss: 3.0807 - val_acc: 0.5052\n",
      "Epoch 35/100\n",
      "7859/7859 [==============================] - 1s 97us/step - loss: 0.0605 - acc: 0.9822 - val_loss: 3.2939 - val_acc: 0.4891\n",
      "Epoch 36/100\n",
      "7859/7859 [==============================] - 1s 99us/step - loss: 0.0617 - acc: 0.9826 - val_loss: 3.2793 - val_acc: 0.4788\n",
      "Epoch 37/100\n",
      "7859/7859 [==============================] - 1s 103us/step - loss: 0.0609 - acc: 0.9841 - val_loss: 3.3030 - val_acc: 0.4800\n",
      "Epoch 38/100\n",
      "7859/7859 [==============================] - 1s 101us/step - loss: 0.0497 - acc: 0.9847 - val_loss: 3.3164 - val_acc: 0.4937\n",
      "Epoch 39/100\n",
      "7859/7859 [==============================] - 1s 101us/step - loss: 0.0510 - acc: 0.9847 - val_loss: 3.5887 - val_acc: 0.4628\n",
      "Epoch 40/100\n",
      "7859/7859 [==============================] - 1s 99us/step - loss: 0.0435 - acc: 0.9884 - val_loss: 3.3297 - val_acc: 0.4834\n",
      "Epoch 41/100\n",
      "7859/7859 [==============================] - 1s 101us/step - loss: 0.0484 - acc: 0.9864 - val_loss: 3.4688 - val_acc: 0.4811\n",
      "Epoch 42/100\n",
      "7859/7859 [==============================] - 1s 98us/step - loss: 0.0353 - acc: 0.9915 - val_loss: 3.3972 - val_acc: 0.5017\n",
      "Epoch 43/100\n",
      "7859/7859 [==============================] - 1s 97us/step - loss: 0.0447 - acc: 0.9855 - val_loss: 3.4807 - val_acc: 0.4811\n",
      "Epoch 44/100\n",
      "7859/7859 [==============================] - 1s 103us/step - loss: 0.0356 - acc: 0.9894 - val_loss: 3.6309 - val_acc: 0.4639\n",
      "Epoch 45/100\n",
      "7859/7859 [==============================] - 1s 102us/step - loss: 0.0384 - acc: 0.9893 - val_loss: 3.4603 - val_acc: 0.4937\n",
      "Epoch 46/100\n",
      "7859/7859 [==============================] - 1s 103us/step - loss: 0.0285 - acc: 0.9924 - val_loss: 3.4418 - val_acc: 0.4834\n",
      "Epoch 47/100\n",
      "7859/7859 [==============================] - 1s 104us/step - loss: 0.0317 - acc: 0.9894 - val_loss: 3.4300 - val_acc: 0.5120\n",
      "Epoch 48/100\n",
      "7859/7859 [==============================] - 1s 109us/step - loss: 0.0332 - acc: 0.9901 - val_loss: 3.6525 - val_acc: 0.4765\n",
      "Epoch 49/100\n",
      "7859/7859 [==============================] - 1s 100us/step - loss: 0.0284 - acc: 0.9926 - val_loss: 3.5718 - val_acc: 0.4914\n",
      "Epoch 50/100\n",
      "7859/7859 [==============================] - 1s 100us/step - loss: 0.0356 - acc: 0.9902 - val_loss: 3.6954 - val_acc: 0.4914\n",
      "Epoch 51/100\n",
      "7859/7859 [==============================] - 1s 106us/step - loss: 0.0221 - acc: 0.9941 - val_loss: 3.7032 - val_acc: 0.4868\n",
      "Epoch 52/100\n",
      "7859/7859 [==============================] - 1s 106us/step - loss: 0.0214 - acc: 0.9935 - val_loss: 3.7441 - val_acc: 0.5006\n",
      "Epoch 53/100\n",
      "7859/7859 [==============================] - 1s 107us/step - loss: 0.0277 - acc: 0.9913 - val_loss: 3.8202 - val_acc: 0.4994\n",
      "Epoch 54/100\n",
      "7859/7859 [==============================] - 1s 107us/step - loss: 0.0274 - acc: 0.9916 - val_loss: 3.8478 - val_acc: 0.4662\n",
      "Epoch 55/100\n",
      "7859/7859 [==============================] - 1s 106us/step - loss: 0.0225 - acc: 0.9930 - val_loss: 3.8945 - val_acc: 0.4788\n",
      "Epoch 56/100\n",
      "7859/7859 [==============================] - 1s 107us/step - loss: 0.0213 - acc: 0.9939 - val_loss: 3.7575 - val_acc: 0.4891\n",
      "Epoch 57/100\n",
      "7859/7859 [==============================] - 1s 101us/step - loss: 0.0297 - acc: 0.9929 - val_loss: 3.5158 - val_acc: 0.5109\n",
      "Epoch 58/100\n",
      "7859/7859 [==============================] - 1s 105us/step - loss: 0.0119 - acc: 0.9964 - val_loss: 3.6122 - val_acc: 0.4994\n",
      "Epoch 59/100\n",
      "7859/7859 [==============================] - 1s 104us/step - loss: 0.0294 - acc: 0.9906 - val_loss: 3.8070 - val_acc: 0.4971\n",
      "Epoch 60/100\n",
      "7859/7859 [==============================] - 1s 105us/step - loss: 0.0143 - acc: 0.9963 - val_loss: 3.8482 - val_acc: 0.4845\n",
      "Epoch 61/100\n",
      "7859/7859 [==============================] - 1s 103us/step - loss: 0.0159 - acc: 0.9962 - val_loss: 3.8070 - val_acc: 0.4788\n",
      "Epoch 62/100\n",
      "7859/7859 [==============================] - 1s 105us/step - loss: 0.0187 - acc: 0.9947 - val_loss: 3.8883 - val_acc: 0.4948\n",
      "Epoch 63/100\n",
      "7859/7859 [==============================] - 1s 106us/step - loss: 0.0180 - acc: 0.9941 - val_loss: 3.7383 - val_acc: 0.4891\n",
      "Epoch 64/100\n",
      "7859/7859 [==============================] - 1s 105us/step - loss: 0.0238 - acc: 0.9926 - val_loss: 3.8895 - val_acc: 0.4719\n",
      "Epoch 65/100\n",
      "7859/7859 [==============================] - 1s 108us/step - loss: 0.0148 - acc: 0.9953 - val_loss: 3.9053 - val_acc: 0.4937\n",
      "Epoch 66/100\n",
      "7859/7859 [==============================] - 1s 108us/step - loss: 0.0116 - acc: 0.9969 - val_loss: 4.0502 - val_acc: 0.4800\n",
      "Epoch 67/100\n",
      "7859/7859 [==============================] - 1s 107us/step - loss: 0.0187 - acc: 0.9943 - val_loss: 3.8196 - val_acc: 0.4880\n",
      "Epoch 68/100\n",
      "7859/7859 [==============================] - 1s 107us/step - loss: 0.0089 - acc: 0.9971 - val_loss: 4.0186 - val_acc: 0.4754\n",
      "Epoch 69/100\n",
      "7859/7859 [==============================] - 1s 108us/step - loss: 0.0142 - acc: 0.9955 - val_loss: 4.0389 - val_acc: 0.4800\n",
      "Epoch 70/100\n",
      "7859/7859 [==============================] - 1s 106us/step - loss: 0.0209 - acc: 0.9935 - val_loss: 3.9357 - val_acc: 0.4845\n",
      "Epoch 71/100\n",
      "7859/7859 [==============================] - 1s 104us/step - loss: 0.0177 - acc: 0.9943 - val_loss: 4.0848 - val_acc: 0.4811\n",
      "Epoch 72/100\n",
      "7859/7859 [==============================] - 1s 106us/step - loss: 0.0129 - acc: 0.9963 - val_loss: 3.9739 - val_acc: 0.5052\n",
      "Epoch 73/100\n",
      "7859/7859 [==============================] - 1s 109us/step - loss: 0.0128 - acc: 0.9966 - val_loss: 3.7718 - val_acc: 0.5086\n",
      "Epoch 74/100\n",
      "7859/7859 [==============================] - 1s 108us/step - loss: 0.0095 - acc: 0.9967 - val_loss: 3.9515 - val_acc: 0.5074\n",
      "Epoch 75/100\n",
      "7859/7859 [==============================] - 1s 104us/step - loss: 0.0192 - acc: 0.9938 - val_loss: 4.1465 - val_acc: 0.4926\n",
      "Epoch 76/100\n",
      "7859/7859 [==============================] - 1s 104us/step - loss: 0.0060 - acc: 0.9982 - val_loss: 4.0906 - val_acc: 0.4845\n",
      "Epoch 77/100\n",
      "7859/7859 [==============================] - 1s 105us/step - loss: 0.0207 - acc: 0.9930 - val_loss: 3.8047 - val_acc: 0.5006\n",
      "Epoch 78/100\n",
      "7859/7859 [==============================] - 1s 105us/step - loss: 0.0172 - acc: 0.9941 - val_loss: 4.0919 - val_acc: 0.4891\n",
      "Epoch 79/100\n",
      "7859/7859 [==============================] - 1s 106us/step - loss: 0.0078 - acc: 0.9978 - val_loss: 3.9616 - val_acc: 0.4891\n",
      "Epoch 80/100\n",
      "7859/7859 [==============================] - 1s 105us/step - loss: 0.0148 - acc: 0.9952 - val_loss: 4.0109 - val_acc: 0.5143\n",
      "Epoch 81/100\n",
      "7859/7859 [==============================] - 1s 107us/step - loss: 0.0088 - acc: 0.9968 - val_loss: 4.6480 - val_acc: 0.4502\n",
      "Epoch 82/100\n",
      "7859/7859 [==============================] - 1s 106us/step - loss: 0.0157 - acc: 0.9950 - val_loss: 3.8948 - val_acc: 0.5063\n",
      "Epoch 83/100\n",
      "7859/7859 [==============================] - 1s 105us/step - loss: 0.0132 - acc: 0.9954 - val_loss: 4.0609 - val_acc: 0.5086\n",
      "Epoch 84/100\n",
      "7859/7859 [==============================] - 1s 105us/step - loss: 0.0070 - acc: 0.9977 - val_loss: 4.1432 - val_acc: 0.4971\n",
      "Epoch 85/100\n",
      "7859/7859 [==============================] - 1s 108us/step - loss: 0.0181 - acc: 0.9933 - val_loss: 4.1026 - val_acc: 0.4937\n",
      "Epoch 86/100\n",
      "7859/7859 [==============================] - 1s 105us/step - loss: 0.0192 - acc: 0.9945 - val_loss: 4.0861 - val_acc: 0.4845\n",
      "Epoch 87/100\n",
      "7859/7859 [==============================] - 1s 106us/step - loss: 0.0048 - acc: 0.9982 - val_loss: 3.9477 - val_acc: 0.4948\n",
      "Epoch 88/100\n",
      "7859/7859 [==============================] - 1s 106us/step - loss: 0.0123 - acc: 0.9957 - val_loss: 4.0617 - val_acc: 0.4765\n",
      "Epoch 89/100\n",
      "7859/7859 [==============================] - 1s 105us/step - loss: 0.0171 - acc: 0.9939 - val_loss: 4.1207 - val_acc: 0.4800\n",
      "Epoch 90/100\n",
      "7859/7859 [==============================] - 1s 108us/step - loss: 0.0069 - acc: 0.9975 - val_loss: 4.0555 - val_acc: 0.4948\n",
      "Epoch 91/100\n",
      "7859/7859 [==============================] - 1s 107us/step - loss: 0.0085 - acc: 0.9972 - val_loss: 4.2532 - val_acc: 0.4983\n",
      "Epoch 92/100\n",
      "7859/7859 [==============================] - 1s 107us/step - loss: 0.0072 - acc: 0.9972 - val_loss: 4.0138 - val_acc: 0.4914\n",
      "Epoch 93/100\n",
      "7859/7859 [==============================] - 1s 106us/step - loss: 0.0162 - acc: 0.9941 - val_loss: 4.1537 - val_acc: 0.4926\n",
      "Epoch 94/100\n",
      "7859/7859 [==============================] - 1s 106us/step - loss: 0.0045 - acc: 0.9982 - val_loss: 4.0931 - val_acc: 0.5074\n",
      "Epoch 95/100\n",
      "7859/7859 [==============================] - 1s 109us/step - loss: 0.0167 - acc: 0.9950 - val_loss: 4.1660 - val_acc: 0.5052\n",
      "Epoch 96/100\n",
      "7859/7859 [==============================] - 1s 107us/step - loss: 0.0058 - acc: 0.9983 - val_loss: 4.0890 - val_acc: 0.5143\n",
      "Epoch 97/100\n",
      "7859/7859 [==============================] - 1s 109us/step - loss: 0.0116 - acc: 0.9954 - val_loss: 4.0960 - val_acc: 0.5223\n",
      "Epoch 98/100\n",
      "7859/7859 [==============================] - 1s 107us/step - loss: 0.0054 - acc: 0.9976 - val_loss: 4.5331 - val_acc: 0.4937\n",
      "Epoch 99/100\n",
      "7859/7859 [==============================] - 1s 107us/step - loss: 0.0146 - acc: 0.9948 - val_loss: 4.1341 - val_acc: 0.5006\n",
      "Epoch 100/100\n",
      "7859/7859 [==============================] - 1s 104us/step - loss: 0.0173 - acc: 0.9943 - val_loss: 4.2687 - val_acc: 0.5189\n",
      "Score:  [4.268728547626072, 0.5189003438474387]\n",
      "Train on 7859 samples, validate on 873 samples\n",
      "Epoch 1/100\n",
      "7859/7859 [==============================] - 2s 231us/step - loss: 1.9526 - acc: 0.3151 - val_loss: 1.9258 - val_acc: 0.2967\n",
      "Epoch 2/100\n",
      "7859/7859 [==============================] - 1s 109us/step - loss: 1.5407 - acc: 0.4803 - val_loss: 1.8889 - val_acc: 0.3482\n",
      "Epoch 3/100\n",
      "7859/7859 [==============================] - 1s 112us/step - loss: 1.3506 - acc: 0.5497 - val_loss: 1.8654 - val_acc: 0.3666\n",
      "Epoch 4/100\n",
      "7859/7859 [==============================] - 1s 109us/step - loss: 1.2303 - acc: 0.5886 - val_loss: 1.8998 - val_acc: 0.3803\n",
      "Epoch 5/100\n",
      "7859/7859 [==============================] - 1s 105us/step - loss: 1.1415 - acc: 0.6162 - val_loss: 1.8808 - val_acc: 0.3986\n",
      "Epoch 6/100\n",
      "7859/7859 [==============================] - 1s 107us/step - loss: 1.0828 - acc: 0.6377 - val_loss: 1.9416 - val_acc: 0.3551\n",
      "Epoch 7/100\n",
      "7859/7859 [==============================] - 1s 106us/step - loss: 1.0307 - acc: 0.6577 - val_loss: 1.9774 - val_acc: 0.4021\n",
      "Epoch 8/100\n",
      "7859/7859 [==============================] - 1s 108us/step - loss: 0.9943 - acc: 0.6660 - val_loss: 1.9233 - val_acc: 0.4032\n",
      "Epoch 9/100\n",
      "7859/7859 [==============================] - 1s 108us/step - loss: 0.9440 - acc: 0.6849 - val_loss: 1.9453 - val_acc: 0.4044\n",
      "Epoch 10/100\n",
      "7859/7859 [==============================] - 1s 108us/step - loss: 0.9148 - acc: 0.6960 - val_loss: 2.0013 - val_acc: 0.4101\n",
      "Epoch 11/100\n",
      "7859/7859 [==============================] - 1s 108us/step - loss: 0.8821 - acc: 0.7077 - val_loss: 2.0017 - val_acc: 0.4204\n",
      "Epoch 12/100\n",
      "7859/7859 [==============================] - 1s 109us/step - loss: 0.8629 - acc: 0.7063 - val_loss: 2.0908 - val_acc: 0.3975\n",
      "Epoch 13/100\n",
      "7859/7859 [==============================] - 1s 106us/step - loss: 0.8338 - acc: 0.7201 - val_loss: 2.0089 - val_acc: 0.3998\n",
      "Epoch 14/100\n",
      "7859/7859 [==============================] - 1s 108us/step - loss: 0.7997 - acc: 0.7343 - val_loss: 2.0950 - val_acc: 0.3986\n",
      "Epoch 15/100\n",
      "7859/7859 [==============================] - 1s 164us/step - loss: 0.7836 - acc: 0.7393 - val_loss: 2.3118 - val_acc: 0.3826\n",
      "Epoch 16/100\n",
      "7859/7859 [==============================] - 1s 140us/step - loss: 0.7675 - acc: 0.7384 - val_loss: 2.1449 - val_acc: 0.3940\n",
      "Epoch 17/100\n",
      "7859/7859 [==============================] - 1s 121us/step - loss: 0.7365 - acc: 0.7521 - val_loss: 2.1138 - val_acc: 0.4044\n",
      "Epoch 18/100\n",
      "7859/7859 [==============================] - 1s 114us/step - loss: 0.7255 - acc: 0.7539 - val_loss: 2.2513 - val_acc: 0.4250\n",
      "Epoch 19/100\n",
      "7859/7859 [==============================] - 1s 115us/step - loss: 0.7099 - acc: 0.7612 - val_loss: 2.2778 - val_acc: 0.4376\n",
      "Epoch 20/100\n",
      "7859/7859 [==============================] - 1s 122us/step - loss: 0.6919 - acc: 0.7674 - val_loss: 2.2438 - val_acc: 0.4353\n",
      "Epoch 21/100\n",
      "7859/7859 [==============================] - 1s 131us/step - loss: 0.6742 - acc: 0.7745 - val_loss: 2.2595 - val_acc: 0.4101\n",
      "Epoch 22/100\n",
      "7859/7859 [==============================] - 1s 124us/step - loss: 0.6706 - acc: 0.7722 - val_loss: 2.4074 - val_acc: 0.4261\n",
      "Epoch 23/100\n",
      "7859/7859 [==============================] - 1s 146us/step - loss: 0.6403 - acc: 0.7859 - val_loss: 2.3775 - val_acc: 0.3986\n",
      "Epoch 24/100\n",
      "7859/7859 [==============================] - 1s 128us/step - loss: 0.6395 - acc: 0.7828 - val_loss: 2.4208 - val_acc: 0.4192\n",
      "Epoch 25/100\n",
      "7859/7859 [==============================] - 1s 132us/step - loss: 0.6304 - acc: 0.7886 - val_loss: 2.3984 - val_acc: 0.4387\n",
      "Epoch 26/100\n",
      "7859/7859 [==============================] - 1s 122us/step - loss: 0.6015 - acc: 0.8010 - val_loss: 2.3974 - val_acc: 0.4261\n",
      "Epoch 27/100\n",
      "7859/7859 [==============================] - 1s 120us/step - loss: 0.6100 - acc: 0.7917 - val_loss: 2.4031 - val_acc: 0.4513\n",
      "Epoch 28/100\n",
      "7859/7859 [==============================] - 1s 116us/step - loss: 0.5916 - acc: 0.8042 - val_loss: 2.6049 - val_acc: 0.4353\n",
      "Epoch 29/100\n",
      "7859/7859 [==============================] - 1s 121us/step - loss: 0.5690 - acc: 0.8077 - val_loss: 2.5893 - val_acc: 0.3757\n",
      "Epoch 30/100\n",
      "7859/7859 [==============================] - 1s 118us/step - loss: 0.5713 - acc: 0.8056 - val_loss: 2.6627 - val_acc: 0.4318\n",
      "Epoch 31/100\n",
      "7859/7859 [==============================] - 1s 119us/step - loss: 0.5581 - acc: 0.8074 - val_loss: 2.5025 - val_acc: 0.4192\n",
      "Epoch 32/100\n",
      "7859/7859 [==============================] - 1s 120us/step - loss: 0.5513 - acc: 0.8096 - val_loss: 2.5950 - val_acc: 0.4399\n",
      "Epoch 33/100\n",
      "7859/7859 [==============================] - 1s 122us/step - loss: 0.5386 - acc: 0.8170 - val_loss: 2.6872 - val_acc: 0.4021\n",
      "Epoch 34/100\n",
      "7859/7859 [==============================] - 1s 120us/step - loss: 0.5229 - acc: 0.8203 - val_loss: 2.7070 - val_acc: 0.4158\n",
      "Epoch 35/100\n",
      "7859/7859 [==============================] - 1s 114us/step - loss: 0.5327 - acc: 0.8196 - val_loss: 2.7289 - val_acc: 0.4078\n",
      "Epoch 36/100\n",
      "3840/7859 [=============>................] - ETA: 0s - loss: 0.5225 - acc: 0.8245"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-48c0087277b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m run_k_fold_cv(10, 'accuracies_v3.txt', UNITS, (1, imp_f.importantAudioFeatures.shape[0]),\n\u001b[0;32m----> 2\u001b[0;31m               (1, imp_f.importantImageFeatures.shape[0]), (1, imp_f.importantCombinedFeatures[0]))\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-93b34b771066>\u001b[0m in \u001b[0;36mrun_k_fold_cv\u001b[0;34m(k, acc_file, units, a_shape, im_shape, full_shape)\u001b[0m\n\u001b[1;32m     30\u001b[0m                                          \u001b[0mim_Y_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim_Y_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                                          \u001b[0munits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                                          EPOCHS, i, 'im')\n\u001b[0m\u001b[1;32m     33\u001b[0m         accs[i, 2] = build_and_run_model(full_X_train[:, FULL_MSK], full_X_test[:, FULL_MSK],\n\u001b[1;32m     34\u001b[0m                                          \u001b[0mfull_Y_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_Y_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-90011f2ca30d>\u001b[0m in \u001b[0;36mbuild_and_run_model\u001b[0;34m(X_train, X_test, Y_train, Y_test, units, rows, cols, batch_size, epochs, fold, prefix)\u001b[0m\n\u001b[1;32m     24\u001b[0m              \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m              \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m              validation_data=(X_test, Y_test))\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcallback_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mt_before_callbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mdelta_t_median\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;31m# will be handled by on_epoch_end.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, current, values)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mflush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0mevt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthreading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEvent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m             \u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run_k_fold_cv(10, 'accuracies_v3.txt', UNITS, (1, imp_f.importantAudioFeatures.shape[0]),\n",
    "              (1, imp_f.importantImageFeatures.shape[0]), (1, imp_f.importantCombinedFeatures[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
